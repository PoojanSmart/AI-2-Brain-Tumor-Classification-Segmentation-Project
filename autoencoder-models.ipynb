{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "127fe8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, Dense, InputLayer, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L1,L2,l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras import backend as K\n",
    "from keras.metrics import MeanIoU, Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5497cea",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7df02600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_crosse(y_true, y_pred):\n",
    "    smooth=1\n",
    "    pixels = 512 * 512\n",
    "    \n",
    "    \n",
    "    one_w = 1.0 -(K.sum(K.batch_flatten(y_true), axis=1)/pixels)\n",
    "    zero_w = 1.0 -((pixels-K.sum(K.batch_flatten(y_true), axis=1))/pixels)\n",
    "\n",
    "    initial_loss = tf.losses.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    zero_loss = K.mean( K.batch_flatten(tf.squeeze(tf.cast(y_true == 0, tf.float32), axis = -1) * initial_loss), axis=1)\n",
    "    one_loss = K.mean( K.batch_flatten(tf.squeeze(tf.cast(y_true == 1, tf.float32), axis = -1) * initial_loss), axis=1)\n",
    "    \n",
    "    zero_weighted_loss = (one_w * 100) * zero_loss\n",
    "    one_weighted_loss = (zero_w * 100) * one_loss\n",
    "    \n",
    "    return K.mean(zero_weighted_loss) + K.mean(one_weighted_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f2b166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a16bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1+K.epsilon())) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4684aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_dice_crosse(y_true, y_pred):\n",
    "    bce = BinaryCrossentropy()\n",
    "    return bce(y_true, y_pred) + dice_coef_loss(y_true, y_pred) + focal_loss()(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10ddbedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    y_pred = K.cast(K.greater(y_pred, .5), dtype='float32') # .5 is the threshold\n",
    "    ones = K.sum(K.flatten(y_pred * y_true)) / K.sum(K.flatten(y_true))\n",
    "    y_pred = K.cast(K.equal(y_pred, 0), dtype='float32')\n",
    "    y_true = K.cast(K.equal(y_true, 0), dtype='float32')\n",
    "    zeros = K.sum(K.flatten(y_pred * y_true)) / K.sum(K.flatten(y_true))\n",
    "    return (ones + zeros)/2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb7c9c",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8ba9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1\n",
    "filters = [32,32,64,64,128,128]\n",
    "k_size = [5,5,4,3,3,2]\n",
    "\n",
    "filters_t = [128,64,32,32,16,1]\n",
    "k_size_t = [2,3,3,4,5,5]\n",
    "activation = ['relu','relu','relu','relu','relu','sigmoid']\n",
    "\n",
    "model1 = models.Sequential()\n",
    "\n",
    "#encoder\n",
    "model1.add(InputLayer(input_shape = (512,512,1)))\n",
    "\n",
    "for f,k in zip(filters,k_size): \n",
    "    model1.add(Conv2D(f, kernel_size = k, strides=(1,1), padding=\"same\", activation='relu'))\n",
    "    #autoenc.add(BatchNormalization())\n",
    "    model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#decoder\n",
    "for f,k,a in zip(filters_t,k_size_t,activation): \n",
    "    model1.add(Conv2DTranspose(f, kernel_size=k, strides=(2,2), padding=\"same\", activation=a))\n",
    "    #autoenc.add(BatchNormalization())\n",
    "\n",
    "model1.compile(optimizer = Adam(learning_rate=1e-3), loss=focal_dice_crosse, metrics = [mean_iou, 'accuracy'], run_eagerly=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
